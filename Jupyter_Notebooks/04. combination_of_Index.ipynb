{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all clened CSV files into one Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the time serie data does include all the dates. There are always some gaps due to weekends or missing data. Therefore, I created a new dataframe with complete serie of dates starting from 01.01.2020 - 08.04.2020. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-04-04,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-04-05,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-04-06,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-04-07,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             col\n",
       "0    2019-01-01,\n",
       "1    2019-01-02,\n",
       "2    2019-01-03,\n",
       "3    2019-01-04,\n",
       "4    2019-01-05,\n",
       "..           ...\n",
       "459  2020-04-04,\n",
       "460  2020-04-05,\n",
       "461  2020-04-06,\n",
       "462  2020-04-07,\n",
       "463   2020-04-08\n",
       "\n",
       "[464 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_range(start, end):\n",
    "    r = (end+datetime.timedelta(days=1)-start).days\n",
    "    return [start+datetime.timedelta(days=i) for i in range(r)]\n",
    "\n",
    "start = datetime.date(2019,1,1)\n",
    "end = datetime.date(2020,4,8)\n",
    "dateList = date_range(start, end)\n",
    "\n",
    "dateList\n",
    "dateList_new = \", \".join([str(date) for date in dateList])\n",
    "date = []\n",
    "date = list(dateList_new.split())\n",
    "\n",
    "df_date = pd.DataFrame({'col':date})\n",
    "df_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01,</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02,</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03,</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04,</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05,</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-04-04,</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-04-05,</td>\n",
       "      <td>2020-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-04-06,</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-04-07,</td>\n",
       "      <td>2020-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>2020-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             col       date\n",
       "0    2019-01-01, 2019-01-01\n",
       "1    2019-01-02, 2019-01-02\n",
       "2    2019-01-03, 2019-01-03\n",
       "3    2019-01-04, 2019-01-04\n",
       "4    2019-01-05, 2019-01-05\n",
       "..           ...        ...\n",
       "459  2020-04-04, 2020-04-04\n",
       "460  2020-04-05, 2020-04-05\n",
       "461  2020-04-06, 2020-04-06\n",
       "462  2020-04-07, 2020-04-07\n",
       "463   2020-04-08 2020-04-08\n",
       "\n",
       "[464 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a table with all dates for the given range to time, such that we can do a left\n",
    "df_date[\"date\"]=df_date[\"col\"].str.replace(\",\",\"\")\n",
    "df_date[\"date\"]= pd.to_datetime(df_date[\"col\"])\n",
    "df_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to left-join 2 dataframes based on the dates\n",
    "\n",
    "Left join is important due the missing values in some of the data series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df (df1, df2):\n",
    "    df2[\"date\"]=pd.to_datetime(df2[\"date\"])\n",
    "    df_new = df1.merge(right = df2,\n",
    "                      how = \"left\",\n",
    "                      on = \"date\")\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all the clean CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAC_40\n",
    "df_CAC = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/CAC_40_FR_clean.csv\")\n",
    "\n",
    "#DAX_30\n",
    "df_DAX = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/DAX_30_DE_clean.csv\")\n",
    "\n",
    "#DOW_JONES\n",
    "df_DJ = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/DOW_JONES_US_clean\").drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "#FTSE_MIB\n",
    "df_FTSE = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/FTSE_MIB_IT_clean\")\n",
    "columns = [\"date\",\"FTSE_IT_value\"]\n",
    "df_FTSE.columns = columns\n",
    "\n",
    "#IBEX\n",
    "df_IBEX = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/IBEX_35_SP_clean.csv\").drop(columns=\"Unnamed: 0\")\n",
    "columns = [\"date\",\"IBEX_value\"]\n",
    "df_IBEX.columns = columns\n",
    "\n",
    "# NASDAQ_clean\n",
    "df_NASDAQ = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/NASDAQ_clean\").drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "#NIKKEI\n",
    "df_NIKKEI = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/NIKKEI_225_JP_clean.csv\")\n",
    "\n",
    "#SP_500\n",
    "df_SP = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/S&P_500_US_clean.csv\")\n",
    "\n",
    "#SSE\n",
    "df_SSE = pd.read_csv(\"/Users/Tianwang/ironhack/git/Data_Thief_Project_Team_Wall-e/data/archiv/02_cleaned_index_data/SSE_CN_clean.csv\").drop(columns=\"Unnamed: 0\")\n",
    "columns=[\"date\",\"SSE_value\"]\n",
    "df_SSE.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The combination of loop and function combined all cleaned CSV files into 1 dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tested the function combine_df on 2 of the dataframes first and it worked out. \n",
    "\n",
    "So I moved on the created a loop to do the work. \n",
    "\n",
    "Note: In the beginning, the loop constantly showed a 'key error', I went thru the process manually to debug. And I found that in the SSE file, the column \"date\" was written as \"Date\". Therefore, the loop didn't work. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cac_40_fr_index</th>\n",
       "      <th>dax_30_de_index</th>\n",
       "      <th>DOW_JONES_value</th>\n",
       "      <th>FTSE_IT_value</th>\n",
       "      <th>IBEX_value</th>\n",
       "      <th>NASDAQ_US_value</th>\n",
       "      <th>value_NIKKEI_25_JP</th>\n",
       "      <th>value_SP_500_US</th>\n",
       "      <th>SSE_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>4689.39</td>\n",
       "      <td>10580.19</td>\n",
       "      <td>23346.24</td>\n",
       "      <td>18330.99</td>\n",
       "      <td>8550.0</td>\n",
       "      <td>7263.870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2510.03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>4611.49</td>\n",
       "      <td>10416.66</td>\n",
       "      <td>22686.22</td>\n",
       "      <td>18218.40</td>\n",
       "      <td>8523.3</td>\n",
       "      <td>7595.350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2447.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>4737.12</td>\n",
       "      <td>10767.69</td>\n",
       "      <td>23433.16</td>\n",
       "      <td>18831.79</td>\n",
       "      <td>8737.8</td>\n",
       "      <td>7828.910</td>\n",
       "      <td>19561.96</td>\n",
       "      <td>2531.94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8049.641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>4346.14</td>\n",
       "      <td>10075.17</td>\n",
       "      <td>22679.99</td>\n",
       "      <td>17039.31</td>\n",
       "      <td>6844.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18576.30</td>\n",
       "      <td>2663.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>4438.27</td>\n",
       "      <td>10356.70</td>\n",
       "      <td>22653.86</td>\n",
       "      <td>17411.72</td>\n",
       "      <td>7002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18950.18</td>\n",
       "      <td>2659.41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2815.368652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  cac_40_fr_index  dax_30_de_index  DOW_JONES_value  \\\n",
       "0   2019-01-01              NaN              NaN              NaN   \n",
       "1   2019-01-02          4689.39         10580.19         23346.24   \n",
       "2   2019-01-03          4611.49         10416.66         22686.22   \n",
       "3   2019-01-04          4737.12         10767.69         23433.16   \n",
       "4   2019-01-05              NaN              NaN              NaN   \n",
       "..         ...              ...              ...              ...   \n",
       "459 2020-04-04              NaN              NaN              NaN   \n",
       "460 2020-04-05              NaN              NaN              NaN   \n",
       "461 2020-04-06          4346.14         10075.17         22679.99   \n",
       "462 2020-04-07          4438.27         10356.70         22653.86   \n",
       "463 2020-04-08              NaN              NaN              NaN   \n",
       "\n",
       "     FTSE_IT_value  IBEX_value  NASDAQ_US_value  value_NIKKEI_25_JP  \\\n",
       "0              NaN         NaN              NaN                 NaN   \n",
       "1         18330.99      8550.0         7263.870                 NaN   \n",
       "2         18218.40      8523.3         7595.350                 NaN   \n",
       "3         18831.79      8737.8         7828.910            19561.96   \n",
       "4              NaN         NaN         8049.641                 NaN   \n",
       "..             ...         ...              ...                 ...   \n",
       "459            NaN         NaN              NaN                 NaN   \n",
       "460            NaN         NaN              NaN                 NaN   \n",
       "461       17039.31      6844.3              NaN            18576.30   \n",
       "462       17411.72      7002.0              NaN            18950.18   \n",
       "463            NaN         NaN              NaN                 NaN   \n",
       "\n",
       "     value_SP_500_US    SSE_value  \n",
       "0                NaN          NaN  \n",
       "1            2510.03          NaN  \n",
       "2            2447.89          NaN  \n",
       "3            2531.94          NaN  \n",
       "4                NaN          NaN  \n",
       "..               ...          ...  \n",
       "459              NaN          NaN  \n",
       "460              NaN          NaN  \n",
       "461          2663.68          NaN  \n",
       "462          2659.41          NaN  \n",
       "463              NaN  2815.368652  \n",
       "\n",
       "[464 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_index = [df_CAC, df_DAX, df_DJ, df_FTSE, df_IBEX, df_NASDAQ, df_NIKKEI, df_SP,df_SSE]\n",
    "df_new = df_date\n",
    "for index in list_of_index:\n",
    "    df_new = combine_df(df_new, index)\n",
    "    \n",
    "df_final = df_new.copy()\n",
    "df_final = df_final.drop(\"col\",1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the process of debugging, we have also created another loop to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def combine_df_test (df1, df2):\n",
    "#    df_new = df1\n",
    "#    for index in df2:\n",
    "#        index[\"date\"]=pd.to_datetime(index[\"date\"])\n",
    "#        df_new = df_new.merge(right = index,\n",
    "#                          how = \"left\",\n",
    "#                          on = \"date\")\n",
    "#    return df_new\n",
    "#\n",
    "#list_of_index = [df_CAC, df_DAX, df_DJ, df_FTSE, df_IBEX, df_NASDAQ, df_NIKKEI, df_SP,df_SSE]\n",
    "#combine_df_test(df_date, list_of_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_pickle(\"combined_financial_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
